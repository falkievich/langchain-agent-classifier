# LangChain Agent Classifier

> Sistema de agente inteligente basado en **LangChain** y **FastAPI** para procesamiento automatizado de expedientes judiciales mediante Large Language Models (LLM).

[![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](Dockerfile)
[![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)](requirements.txt)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green?logo=fastapi)](app.py)

---

## ğŸ“‹ Tabla de Contenidos

- [ğŸš€ Quick Start](#-quick-start)
  - [OpciÃ³n 1: Docker (Recomendado)](#opciÃ³n-1-docker-recomendado)
  - [OpciÃ³n 2: EjecuciÃ³n Local](#opciÃ³n-2-ejecuciÃ³n-local)
- [ğŸ—ï¸ Arquitectura](#arquitectura)
- [âš™ï¸ Funcionalidades](#ï¸-funcionalidades)
  - [1ï¸âƒ£ Agente LLM con Tools](#1ï¸âƒ£-agente-llm-con-tools)
  - [2ï¸âƒ£ ExtracciÃ³n de Personas con LLM](#2ï¸âƒ£-extracciÃ³n-de-personas-con-llm)
- [ğŸ” ConfiguraciÃ³n](#configuraciÃ³n)


---

## ğŸš€ Quick Start

### OpciÃ³n 1: Docker (Recomendado)

```bash
# 1. Clonar el repositorio
git clone <repo-url>
cd langchain-agent-classifier

# 2. Configurar .env (ver secciÃ³n "ConfiguraciÃ³n")

# 3. Build y Start
docker-compose build
docker-compose up -d

# 4. Ver logs en tiempo real
docker-compose logs -f

# 5. Health check
curl http://localhost:8000/api/extract-persons/health

# 6. Detener contenedores
docker-compose down

```

### OpciÃ³n 2: Local

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Configurar .env (ver secciÃ³n "ConfiguraciÃ³n")

# 3. Ejecutar servidor
uvicorn app:app --reload --host 0.0.0.0 --port 8000

# 4. Health check
curl http://localhost:8000/api/extract-persons/health

```

---


---

## âš™ï¸ Funcionalidades

### 1ï¸âƒ£ Agente LLM con Tools

> Sistema de agente inteligente que analiza expedientes judiciales y responde preguntas en lenguaje natural usando herramientas especializadas.

#### ğŸ“ Endpoint

```http
POST /api/agent_llm
```

#### ğŸ“¥ ParÃ¡metros

| ParÃ¡metro | Tipo | DescripciÃ³n |
|-----------|------|-------------|
| `user_prompt` | Form (string) | Pregunta en lenguaje natural |
| `json_file` | File | JSON con datos del expediente |

#### ğŸ”„ Pipeline de EjecuciÃ³n

```
Usuario
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARACIÃ“N (agent_service.py)                      â”‚
â”‚  â€¢ Cargar todas las tools disponibles                  â”‚
â”‚  â€¢ Inicializar LLM (MODEL_ID)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PLANNER (planning.py)                                â”‚
â”‚  â€¢ LLM analiza el prompt                                â”‚
â”‚  â€¢ Selecciona tools relevantes                          â”‚
â”‚  â€¢ Genera plan de ejecuciÃ³n:                            â”‚
â”‚    [{tool: "buscar_persona", args: ["rol", "Actor"]}]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. EXECUTOR (execution.py)                              â”‚
â”‚  â€¢ Ejecuta tools EN PARALELO                            â”‚
â”‚  â€¢ Consolida resultados                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. FINALIZER (execution.py)                             â”‚
â”‚  â€¢ LLM sintetiza resultados                             â”‚
â”‚  â€¢ Responde en lenguaje natural                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
               Respuesta al Usuario
```

#### ğŸ› ï¸ Tools Disponibles

<details>
<summary><b>Listados</b></summary>

- `listar_todo(dominio)` - Lista todos los elementos de un dominio
  - Dominios: `persona`, `abogado`, `expediente`, `radicacion`, `dependencia`, `delito`, `funcionario`, `causa`, `clasificador`

</details>

<details>
<summary><b>BÃºsquedas Globales</b></summary>

**Personas**
- `buscar_persona(filtro, valor)` - BÃºsqueda general
- `buscar_persona_por_nombre(nombre)` - Por nombre
- `buscar_persona_por_dni(dni)` - Por DNI
- `buscar_persona_por_rol(rol)` - Por rol

**Abogados**
- `buscar_abogado(filtro, valor)` - BÃºsqueda general
- `buscar_clientes_de_abogado(nombre_abogado)` - Clientes
- `buscar_abogado_por_cliente(nombre_cliente)` - Por cliente

**Expedientes**
- `buscar_expediente(filtro, valor)` - BÃºsqueda general
- `obtener_info_general_expediente()` - Info general

**Radicaciones**
- `buscar_radicacion(filtro, valor)` - BÃºsqueda general

**Dependencias**
- `buscar_dependencia(filtro, valor)` - BÃºsqueda general

</details>

<details>
<summary><b>BÃºsquedas por Dominio</b></summary>

- `buscar_en_dominio(dominio, filtro, valor)` - BÃºsqueda genÃ©rica

</details>

#### ğŸ“ Ejemplo de Uso

**Request:**
```bash
curl -X POST http://localhost:8000/api/agent_llm \
  -F "user_prompt=Â¿QuiÃ©n es el demandante y su abogado?" \
  -F "json_file=@expediente.json"
```

**Response:**
```json
{
  "response": "El demandante es Juan PÃ©rez (DNI 12345678), representado por la abogada MarÃ­a LÃ³pez (MatrÃ­cula MP-2025-001)."
}
```

---

### 2ï¸âƒ£ ExtracciÃ³n de Personas con LLM

> Sistema especializado que extrae y consolida automÃ¡ticamente TODAS las personas mencionadas en un expediente judicial.

#### ğŸ“ Endpoint

```http
POST /api/extract-persons-with-llm
```

#### ğŸ“¥ ParÃ¡metros

| ParÃ¡metro | Tipo | DescripciÃ³n |
|-----------|------|-------------|
| `json_txt_file` | File | JSON o TXT con datos del expediente |

#### ğŸ”„ Pipeline de EjecuciÃ³n

```
Usuario
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CARGA DEL JSON                                       â”‚
â”‚  â€¢ Lee el archivo                                       â”‚
â”‚  â€¢ Valida formato                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. EXTRACCIÃ“N (person_extraction_service.py)            â”‚
â”‚  â€¢ Inicializa LLM (MODEL_ID_2)                          â”‚
â”‚  â€¢ Prompt especializado para extraer personas           â”‚
â”‚  â€¢ Busca en TODAS las secciones del JSON                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CONSOLIDACIÃ“N                                        â”‚
â”‚  â€¢ Identifica duplicados por:                           â”‚
â”‚    - DNI, CUIL, nombre_completo                         â”‚
â”‚  â€¢ Mezcla roles y datos                                 â”‚
â”‚  â€¢ Genera una entrada Ãºnica por persona                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
         JSON Estructurado con Personas
```

#### âœ¨ CaracterÃ­sticas

| Feature | DescripciÃ³n |
|---------|-------------|
| âœ… **ConsolidaciÃ³n AutomÃ¡tica** | Detecta y fusiona personas duplicadas |
| âœ… **ExtracciÃ³n Exhaustiva** | Busca en TODAS las secciones del JSON |
| âœ… **Roles MÃºltiples** | Agrupa todos los roles de una persona |
| âœ… **Datos Completos** | Mezcla informaciÃ³n de todas las fuentes |

#### ğŸ“ Ejemplo de ConsolidaciÃ³n

**Entrada:**
```json
{
  "personas_legajo": [
    {
      "nombre_completo": "MarÃ­a PÃ©rez",
      "dni": "87654321",
      "rol": "DILIGENCIANTE",
      "genero": "FEMENINO"
    }
  ],
  "abogados_legajo": [
    {
      "nombre_completo": "MarÃ­a PÃ©rez",
      "dni": "87654321",
      "matricula": "MP-2025-001"
    }
  ]
}
```

**Salida (Consolidada):**
```json
{
  "personas": [
    {
      "nombre_completo": "MarÃ­a PÃ©rez",
      "roles": ["DILIGENCIANTE", "ABOGADO"],
      "datos_adicionales": {
        "dni": "87654321",
        "cuil": "27-87654321-9",
        "matricula": "MP-2025-001",
        "genero": "FEMENINO"
      }
    }
  ],
  "total": 1
}
```

#### ğŸ©º Health Check

```bash
curl http://localhost:8000/api/extract-persons/health
```

---

## ğŸ” ConfiguraciÃ³n

### Variables de Entorno

Crear archivo `.env` en la raÃ­z del proyecto con la siguiente estructura:

```bash
# ============================================================
# LLM Server Configuration
# ============================================================
BASE_URL=<url_del_servidor_llm>
API_KEY=<tu_api_key>

# ============================================================
# Model Configuration
# ============================================================
MODEL_ID=<modelo_principal>          # Modelo para agente con tools
MODEL_ID_2=<modelo_extraccion>       # Modelo para extracciÃ³n de personas
SMALL_MODEL_ID=<modelo_pequeÃ±o>      # Modelo pequeÃ±o (uso futuro)

# ============================================================
# LangChain Observability (Opcional)
# ============================================================
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=<tu_langchain_api_key>
# LANGCHAIN_PROJECT=langchain-agent-classifier
```

**Ejemplo de configuraciÃ³n:**
- `BASE_URL`: URL completa del servidor LLM compatible con OpenAI API (ej: `http://servidor:puerto/api/chat/completions`)
- `API_KEY`: Clave de autenticaciÃ³n del servidor LLM
- `MODEL_ID`: Nombre del modelo LLM para el agente (ej: `gpt-oss:20b`, `llama2:13b`)
- `MODEL_ID_2`: Nombre del modelo LLM para extracciÃ³n de personas
- `SMALL_MODEL_ID`: Modelo pequeÃ±o para optimizaciones futuras

### Endpoints

| Endpoint | Method | DescripciÃ³n |
|----------|--------|-------------|
| `/api/agent_llm` | POST | Agente LLM con tools |
| `/api/extract-persons-with-llm` | POST | ExtracciÃ³n de personas |
| `/api/extract-persons/health` | GET | Health check |

---

