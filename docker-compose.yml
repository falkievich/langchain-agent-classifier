version: '3.8'

name: langchain-agent-classifier  # Evitar que colisione con otros compose

services:
  langchain-agent-backend:
    build:
      context: .
      dockerfile: Dockerfile
      # Habilitar BuildKit cache para acelerar rebuilds
      cache_from:
        - langchain-agent-classifier-backend:latest
    image: langchain-agent-classifier-backend:latest
    container_name: langchain-agent-classifier-backend
    ports:
      - "8000:8000"
    volumes:
      # Montar el .env para que lea las variables de entorno
      - ./.env:/app/.env:ro
    # Leer variables de entorno desde .env (más idiomático en Compose)
    env_file:
      - ./.env
    environment:
      # Variables de entorno
      - PYTHONUNBUFFERED=1
    # Mapear el nombre host.docker.internal al gateway del host para que desde dentro del contenedor
    # puedas llegar al servicio Ollama publicado en el host (puerto 3000)
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    networks:
      - langchain-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/extract-persons/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  langchain-network:
    driver: bridge
